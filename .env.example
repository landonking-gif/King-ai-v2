# Database
DATABASE_URL=postgresql+asyncpg://king:password@localhost:5432/kingai
REDIS_URL=redis://localhost:6379

# LLM Providers
# Primary: vLLM for production
VLLM_URL=http://inference-alb.internal:8080
VLLM_MODEL=meta-llama/Llama-3.1-70B-Instruct

# Secondary: Ollama for development/fallback
OLLAMA_URL=http://ec2-54-196-74-136.compute-1.amazonaws.com:11434
OLLAMA_MODEL=llama3.1:8b

# Tertiary: Cloud fallbacks
GEMINI_API_KEY=your-gemini-key
ANTHROPIC_API_KEY=your-claude-key

# Vector Store
PINECONE_API_KEY=
PINECONE_INDEX=king-ai
PINECONE_ENV=us-east-1

# AWS
AWS_REGION=us-east-1
SQS_INFERENCE_QUEUE=king-ai-inference-queue
S3_ARTIFACTS_BUCKET=king-ai-artifacts

# Monitoring
DD_ENABLED=true
DD_API_KEY=your-datadog-key
DD_APP_KEY=your-datadog-app-key

# Security
JWT_SECRET=your-super-secret-key-change-in-production
API_RATE_LIMIT=100

# Feature Flags
ENABLE_AUTONOMOUS_MODE=false
ENABLE_SELF_MODIFICATION=true
ENABLE_VLLM=true

# Risk Profile
RISK_PROFILE=moderate  # conservative, moderate, aggressive
MAX_EVOLUTIONS_PER_HOUR=5
EVOLUTION_CONFIDENCE_THRESHOLD=0.8

# API
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# Supplier Integration
# AliExpress API credentials
ALIEXPRESS_APP_KEY=your_app_key
ALIEXPRESS_APP_SECRET=your_secret
ALIEXPRESS_TRACKING_ID=your_tracking_id

# CJ Dropshipping API credentials
CJ_API_KEY=your_cj_api_key
